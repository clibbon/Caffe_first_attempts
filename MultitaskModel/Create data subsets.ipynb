{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Script is used to separate the images into training and testing sets. There are 11 labels: lake, plants, window, buildings, grass, animal, water, person, clouds, sky, and NA]. In some images multiple labels may apply, in others, just one. This first part of the script removes all images which belong to NA or multiple categories.\n",
    "\n",
    "When running the set for the first time, I discover that some files contain no information. To get around this I made a list of all the files which were invalid. The single labels need to be modified to not include these invalid instances. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "labels = open(\"labels_none_missing.txt\", \"r\") # Open the labels file\n",
    "newlabels = open(\"singlelabels.txt\",\"wb\")\n",
    "values = dict()\n",
    "for index, lab in enumerate(['lake', 'plants', 'window', 'buildings',\n",
    "                             'grass', 'animal', 'water', 'person',\n",
    "                             'clouds', 'sky', 'NA']):\n",
    "    values[lab] = index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is also a really good time to count how many of each class we have. Since we now have to also check if that exists in the missing info list, we now need to import mmap. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class_freqs = np.zeros(10)\n",
    "for line in labels:\n",
    "    words = line.split()\n",
    "    # If length is 2 we have only a filename and a label\n",
    "    if len(words) == 2:\n",
    "        if words[1] != 'NA':\n",
    "            string_to_write = words[0] + ' ' + str(values[words[1]]) + '\\n'\n",
    "            newlabels.write(string_to_write)\n",
    "            class_freqs[values[words[1]]] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the first line to check that we've done things properly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "173.jpg 7\n",
      "\n"
     ]
    }
   ],
   "source": [
    "newlabels.close()\n",
    "labels.close()\n",
    "newlabels = open(\"singlelabels.txt\",\"r\")\n",
    "print newlabels.readline()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And report on how many of each class we have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number containing lake is 271\n",
      "Number containing plants is 5591\n",
      "Number containing window is 5220\n",
      "Number containing buildings is 2707\n",
      "Number containing grass is 3207\n",
      "Number containing animal is 19237\n",
      "Number containing water is 5663\n",
      "Number containing person is 34551\n",
      "Number containing clouds is 3353\n",
      "Number containing sky is 9874\n"
     ]
    }
   ],
   "source": [
    "for index, lab in enumerate(['lake', 'plants', 'window', 'buildings',\n",
    "                             'grass', 'animal', 'water', 'person',\n",
    "                             'clouds', 'sky']):\n",
    "    print \"Number containing {} is {:.0f}\".format(lab, class_freqs[index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now these are split into training and testing sets, based on a split of 80% test 10% validation 10% train. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 89739 images. These are split into the three groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nItems = int(sum(class_freqs))\n",
    "import random as r\n",
    "positions = range(0,nItems)\n",
    "r.shuffle(positions)\n",
    "train_idx = positions[:int(nItems*0.8)]\n",
    "val_idx = positions[int(nItems*0.8)+1:int(nItems*0.9)]\n",
    "test_idx = positions[int(nItems*0.9)+1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labels = open(\"singlelabels.txt\", \"r\") # Open the labels file\n",
    "test_labels = open(\"singlelabels_test.txt\",\"wb\")\n",
    "train_labels = open(\"singlelabels_train.txt\",\"wb\")\n",
    "val_labels = open(\"singlelabels_val.txt\",\"wb\")\n",
    "for i, line in enumerate(labels):\n",
    "    if i in test_idx:\n",
    "        test_labels.write(line)\n",
    "    if i in train_idx:\n",
    "        train_labels.write(line)\n",
    "    if i in val_idx:\n",
    "        val_labels.write(line)\n",
    "test_labels.close()\n",
    "train_labels.close()\n",
    "val_labels.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before beginning the multitask model, lets see how often pairs of categories occur together. This can help guide which should be the first grouping to be put together."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "For the multitask model, first a simple model is made with two categories, both of which are binary problems, trained on the same net. The data is processed so that the included labels are now person, and animal. Hopefully two similar problems. The dataset then contains three different classes, contains just person, just animal, or person and animal. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# The labels currently in use\n",
    "labelList = ['sky','clouds']\n",
    "values = dict()\n",
    "for index, lab in enumerate(labelList):\n",
    "    values[lab] = index\n",
    "newlabels = open(\"./Multilabel_two_classes/labels.txt\",\"wb\")\n",
    "labels = open(\"labels_none_missing.txt\", \"r\") # Open the labels file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class_freqs = np.zeros(3)\n",
    "\n",
    "for line in labels:\n",
    "    words = line.split()\n",
    "    # If multiple labels\n",
    "    isSingleAndInList = len(words) == 2 and words[1] in labelList\n",
    "    isInList = map(lambda x: x in labelList, words[1:])\n",
    "    if isSingleAndInList or all(isInList):\n",
    "        # Find which labels are present and convert to [0 1] format\n",
    "        label_txt = [int(y) for y in map(lambda x: x in words[1:],labelList)]\n",
    "        string_to_write = words[0] + ' ' + str(label_txt) + '\\n'\n",
    "        newlabels.write(string_to_write)\n",
    "        class_freqs[(label_txt[0] + 2*label_txt[1])-1] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[  9874.   3353.  15636.]\n"
     ]
    }
   ],
   "source": [
    "line =  labels.readline()\n",
    "print line\n",
    "print class_freqs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we only have 740 instances of people and animals occuring in the same space. Useing the simpler imagenet architecture from the base caffe library since we have relatively few training cases. Better would be to use sky and clouds. These represent a difficult situation to classify seperately and recognise together! Now new labels lists are made for the training and validation steps. These are two_class_train and two_class_test. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pTrain = 0.8 # Therefore pTest is 0.2\n",
    "\n",
    "nItems = int(sum(class_freqs))\n",
    "import random as r\n",
    "positions = range(0,nItems)\n",
    "r.shuffle(positions)\n",
    "train_idx = positions[:int(nItems*pTrain)]\n",
    "test_idx = positions[int(nItems*pTrain)+1:]\n",
    "\n",
    "# Loop through and write to the new files.\n",
    "labels = open(\"./Multilabel_two_classes/labels.txt\",\"r\") # Open the labels file\n",
    "test_labels = open(\"./Multilabel_two_classes/two_class_test.txt\",\"wb\")\n",
    "train_labels = open(\"./Multilabel_two_classes/two_class_train.txt\",\"wb\")\n",
    "for i, line in enumerate(labels):\n",
    "    if i in test_idx:\n",
    "        test_labels.write(line)\n",
    "    if i in train_idx:\n",
    "        train_labels.write(line)\n",
    "test_labels.close()\n",
    "train_labels.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now also add labels for the binary classifier. Here two seperate classifiers will be trained, then the results will have to be compiled to give the multilabel version. As such the labels will be for each - [cloud present cloud not present], class 1 being present, class two being not present.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labelList = ['sky','clouds']\n",
    "skylabels = open(\"./Multilabel_binary/sky_labels.txt\",\"wb\")\n",
    "cloudlabels = open(\"./Multilabel_binary/cloud_labels.txt\",\"wb\")\n",
    "labels = open(\"labels_none_missing.txt\", \"r\") # Open the labels file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for line in labels:\n",
    "    words = line.split()\n",
    "    # If multiple labels\n",
    "    isSingleAndInList = (len(words) == 2) and (words[1] in labelList)\n",
    "    isInList = map(lambda x: x in labelList, words[1:])\n",
    "    if isSingleAndInList:\n",
    "        if words[1] == 'clouds':\n",
    "            cloudLabel = 1\n",
    "            skyLabel = 0\n",
    "        elif words[1] == 'sky':\n",
    "            cloudLabel = 0\n",
    "            skyLabel = 1\n",
    "    elif all(isInList):\n",
    "        cloudLabel = 1\n",
    "        skyLabel = 1\n",
    "    if isSingleAndInList or all(isInList):\n",
    "        cloud_to_write = words[0] + ' ' + str(cloudLabel) + '\\n'\n",
    "        sky_to_write = words[0] + ' ' + str(skyLabel) + '\\n'\n",
    "        skylabels.write(sky_to_write)\n",
    "        cloudlabels.write(cloud_to_write)\n",
    "skylabels.close()\n",
    "cloudlabels.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Write the test and train sets for these two.\n",
    "# Loop through and write to the new files.\n",
    "skylabel = \"./Multilabel_binary/sky_labels.txt\"\n",
    "skylabel_train = \"./Multilabel_binary/sky_labels_train.txt\"\n",
    "skylabel_test = \"./Multilabel_binary/sky_labels_test.txt\"\n",
    "\n",
    "cloudlabel = \"./Multilabel_binary/cloud_labels.txt\"\n",
    "cloudlabel_train = \"./Multilabel_binary/cloud_labels_train.txt\"\n",
    "cloudlabel_test = \"./Multilabel_binary/cloud_labels_test.txt\"\n",
    "\n",
    "splittxtfile(skylabel, skylabel_train, skylabel_test, test_idx)\n",
    "splittxtfile(cloudlabel, cloudlabel_train, cloudlabel_test, test_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def splittxtfile(labelFile, trainFile, testFile, test_idx):\n",
    "    '''\n",
    "    labelFile - file containing the labels\n",
    "    testFile - file to write test labels to\n",
    "    trainFile - file to write train labels to\n",
    "    testIdx - index to line belonging to the test file\n",
    "    '''\n",
    "    \n",
    "    labels = open(labelFile,\"r\") # Open the labels file\n",
    "    test_labels = open(testFile,\"wb\")\n",
    "    train_labels = open(trainFile,\"wb\")\n",
    "    for i, line in enumerate(labels):\n",
    "        if i in test_idx:\n",
    "            test_labels.write(line)\n",
    "        else:\n",
    "            train_labels.write(line)\n",
    "    test_labels.close()\n",
    "    train_labels.close()\n",
    "    labels.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
